{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "#curr_pth = os.path.abspath('../..')\n",
    "import sys\n",
    "#sys.path.append(curr_pth)\n",
    "#curr_pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method(\"spawn\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import bystander\n",
    "from bystander.dataset import *\n",
    "from bystander.data_preprocess import *\n",
    "from bystander.utilities import *\n",
    "from bystander.run_workflow import *\n",
    "import torch.multiprocessing as mp\n",
    "import datetime\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'proportion_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y7/x39w3zs508jdpw3g1_v7k83w0000gp/T/ipykernel_4670/3767543411.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m  \u001b[0mproportion_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_workflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_partition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meditor_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mversion_name\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#1. read data from disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcurr_pth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'proportion_model'"
     ]
    }
   ],
   "source": [
    "from  proportion_model.src.run_workflow import train_test_partition\n",
    "def main(editor_name, input_type,version_name ):\n",
    "\n",
    "    #1. read data from disk\n",
    "    curr_pth = os.path.abspath('../')\n",
    "    data_dir = create_directory(os.path.join(curr_pth, 'dataset',input_type))\n",
    "    suffix = 'proportions_encenc_two_model'\n",
    "    #suffix = 'DeepBE'\n",
    "    fname = f'{editor_name}_{suffix}'\n",
    "    target_data_dir = create_directory(os.path.join(data_dir,fname))\n",
    "    dpartitions = ReaderWriter.read_data(os.path.join(target_data_dir, f'data_partitions.pkl'))\n",
    "    num_runs = len(dpartitions)\n",
    "    datatensor_partitions =  ReaderWriter.read_data(os.path.join(target_data_dir, f'dtensor_partitions.torch'))\n",
    "    ## run for only one partition\n",
    "    #datatensor_partitions = {0:datatensor_partitions[0], 1:datatensor_partitions[1]}\n",
    "    #2. set up environment, device, parameters\n",
    "    #print(len(datatensor_partitions))\n",
    "    gpu_indices = list(range(len(dpartitions)))\n",
    "    run_gpu_maps = {i:indx for i, indx in enumerate(gpu_indices)}\n",
    "\n",
    "    k = 5\n",
    "    embed_dim = 128\n",
    "    num_attn_heads = 8\n",
    "    num_trf_units = 1\n",
    "    pdropout = 0.25\n",
    "    activ_func = nn.ReLU()\n",
    "    multp_factor = 2\n",
    "    multihead_type = 'Narrow'\n",
    "    weight_decay = 1e-4\n",
    "    batch_size = 400\n",
    "    #batch_size = 40\n",
    "    num_epochs = 150\n",
    "    #num_epochs = 2\n",
    "    optim_tup = None\n",
    "    experiment_desc = f'{fname}_schwank'\n",
    "    # possible losses are {'klloss', 'CEloss', 'MSEloss'}\n",
    "    loss_func = 'klloss'\n",
    "    # loss_func = 'CEloss'\n",
    "    # loss_func = 'MSEloss'\n",
    "    trf_tup = (embed_dim, \n",
    "               num_attn_heads, \n",
    "               num_trf_units, \n",
    "               pdropout, \n",
    "               activ_func, \n",
    "               multp_factor, \n",
    "               multihead_type,\n",
    "               weight_decay, \n",
    "               batch_size,\n",
    "               num_epochs)\n",
    "\n",
    "    opt_adendum={'inp_seqlen':20, 'outp_seqlen':20, 'weight_haplotypes':True, 'mask_nontarget_bases':True}\n",
    "\n",
    "    mconfig, options = build_config_map(experiment_desc, 'HaplotypeEncoderEncoder', optim_tup, trf_tup,\n",
    "                                        opt_adendum=opt_adendum,loss_func=loss_func)\n",
    "\n",
    "\n",
    "    if input_type == 'protospacer':\n",
    "        options['inp_seqlen'] = 20\n",
    "        options['outp_seqlen'] = 20\n",
    "\n",
    "    elif input_type == 'protospacer_PAM':\n",
    "        options['inp_seqlen'] = 24\n",
    "        options['outp_seqlen'] = 24\n",
    "\n",
    "    elif input_type == 'protospacer_PAM_overhangs':\n",
    "        options['inp_seqlen'] = 24 + 2*k\n",
    "        options['outp_seqlen'] = 24 + 2*k\n",
    "\n",
    "    else:\n",
    "        print('specify the input type')\n",
    "\n",
    "    #options['num_epochs'] = 300\n",
    "    config_map = mconfig, options\n",
    "    run_gpu_map = {0:run_gpu_maps[0]}\n",
    "\n",
    "\n",
    "    ## 3. define ouput dir\n",
    "    experiment_desc = f'{fname}'\n",
    "    output_dir = os.path.abspath('../../../two_seperate_model/proportion_model/output')\n",
    "    exp_dir = create_directory(os.path.join(output_dir, f'experiment_run_{suffix}', experiment_desc, input_type))\n",
    "\n",
    "    #time_stamp = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "    time_stamp = version_name\n",
    "    tr_val_dir = create_directory(f'exp_{time_stamp}', exp_dir)\n",
    "    print(tr_val_dir)\n",
    "\n",
    "    ## 4. run the model\n",
    "    # https://github.com/facebookresearch/maskrcnn-benchmark/issues/103\n",
    "    # https://github.com/facebookresearch/maskrcnn-benchmark/issues/103\n",
    "    torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "\n",
    "    def spawn_q_process(q_process):\n",
    "        print(\">>> spawning hyperparam search process\")\n",
    "        q_process.start()\n",
    "\n",
    "    def join_q_process(q_process):\n",
    "        q_process.join()\n",
    "        print(\"<<< joined hyperparam search process\")\n",
    "\n",
    "    def create_q_process(datatensor_partition, config_map, tr_val_dir, run_gpu_map, queue):\n",
    "        return mp.Process(target=train_test_partition, args=(datatensor_partition,\n",
    "                                                                                  config_map,\n",
    "                                                                                  tr_val_dir,\n",
    "                                                                                  run_gpu_map, \n",
    "                                                                                  queue))\n",
    "\n",
    "\n",
    "    queue = mp.Queue()\n",
    "    q_processes = []\n",
    "\n",
    "    num_partitions = len(datatensor_partitions)\n",
    "    print('number of partitions:', num_partitions)\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    # n_gpu = len(gpu_indices)\n",
    "    config_map = (mconfig, options)\n",
    "\n",
    "\n",
    "    for q_i in range(min(n_gpu, num_partitions)):\n",
    "        print('q_i:', q_i)\n",
    "        datatensor_partition = {q_i:datatensor_partitions[q_i]}\n",
    "        run_gpu_map = {q_i:run_gpu_maps[q_i]}\n",
    "        q_process = create_q_process(datatensor_partition=datatensor_partition,\n",
    "                                     config_map=config_map,\n",
    "                                     tr_val_dir=tr_val_dir,\n",
    "                                     run_gpu_map=run_gpu_map, \n",
    "                                     queue=queue)\n",
    "        q_processes.append(q_process)\n",
    "        spawn_q_process(q_process)\n",
    "\n",
    "    spawned_processes = n_gpu\n",
    "\n",
    "    print(\"*\"*25)\n",
    "    for q_i in range(num_partitions):\n",
    "    #for q_i in range(1):\n",
    "        join_q_process(q_processes[q_i])\n",
    "        released_gpu_num = queue.get()\n",
    "        print(\"released_gpu_num:\", released_gpu_num)\n",
    "        if(spawned_processes < num_partitions):\n",
    "            q_i_upd = q_i + n_gpu\n",
    "            print('q_i:', q_i, 'q_i_updated:', q_i_upd)\n",
    "            datatensor_partition = {q_i_upd:datatensor_partitions[q_i_upd]}\n",
    "\n",
    "            run_gpu_map = {q_i_upd:released_gpu_num}\n",
    "            q_process = create_q_process(datatensor_partition=datatensor_partition,\n",
    "                                         config_map=config_map,\n",
    "                                         tr_val_dir=tr_val_dir,\n",
    "                                         run_gpu_map=run_gpu_map, \n",
    "                                         queue=queue)\n",
    "            q_processes.append(q_process)\n",
    "            spawn_q_process(q_process)\n",
    "            spawned_processes = spawned_processes + 1\n",
    "\n",
    "    ## 5. peformance report                                                                             # get the performance results on training data\n",
    "    num_runs = len(datatensor_partitions)\n",
    "    train_performance = build_performance_dfs(tr_val_dir, num_runs, 'train', 'continuous')\n",
    "    train_performance.to_csv(tr_val_dir+'/train_peformance.csv')                                                                          # get the performance results on validation dat\n",
    "    build_performance_dfs(tr_val_dir, num_runs, 'validation', 'continuous')                                                                              \n",
    "    test_peformance = build_performance_dfs(tr_val_dir, num_runs, 'test', 'continuous')\n",
    "    test_peformance.to_csv(tr_val_dir+'/test_peformance.csv')  \n",
    "\n",
    "\n",
    "    ## check best epoch for best performing models so far                                                                                ## check best epoch for best performing models so far\n",
    "    for run_num in range(len(datatensor_partitions)):\n",
    "    #for run_num in range(1):\n",
    "        print('run_num:', run_num)\n",
    "        print(ReaderWriter.read_data(os.path.join(f'{tr_val_dir}/train_val/run_{run_num}/model_statedict/best_epoch.pkl')))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utilities import create_directory,ReaderWriter,build_performance_dfs\n",
    "from proportion_model.src.run_workflow import build_config_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for editor_name in ['ABE8e-NG']:\n",
    "#for editor_name in ['ABE8e-SpRY', 'ABE8e-SpCas9','ABEmax-NG','ABEmax-SpCas9','ABEmax-SpRY']:\n",
    "    print('Running dataset:', editor_name)\n",
    "    for input_type in ['protospacer_PAM']: #['protospacer','protospacer_PAM','protospacer_PAM_overhangs']:\n",
    "        print('Running the model with input',input_type)\n",
    "        main(editor_name, input_type,'version_0')\n",
    "        print('The end')                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
